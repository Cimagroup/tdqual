{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023b5fc2",
   "metadata": {},
   "source": [
    "# Housing dataset experiment\n",
    "\n",
    "In this notebook we will try to study the relationship between a given subset $X$ of a dataset $Z$ and the whole dataset. The steps will be the following:\n",
    "1. Load the dataset and normalize its values.\n",
    "2. Choose a random subset of the dataset of a given size.\n",
    "3. Train a MLP on the random subset as a train set and use the rest as test.\n",
    "4. Study the partial matching between the persistence diagrams for the qualitative study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24224d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.spatial.distance as dist\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import gudhi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import itertools\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "import tdqual.topological_data_quality_0 as tdqual\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plots_dir = \"housing_images/\"\n",
    "\n",
    "housing = datasets.fetch_california_housing()\n",
    "\n",
    "Z=housing[\"data\"]\n",
    "Z = preprocessing.normalize(Z)\n",
    "y=housing[\"target\"]\n",
    "n_classes = 4 # +1\n",
    "labels=np.digitize(y,np.linspace(0,5.1,n_classes))-1\n",
    "\n",
    "\n",
    "def subsetZ(Z,labels,size):#,noise_id, size_noise):\n",
    "    ids = np.random.choice(len(Z), replace=False, size=size)\n",
    "    X=Z[ids]\n",
    "    y=labels[ids]\n",
    "    #s=np.shape(S[y==noise_id])\n",
    "    #noise = np.random.normal(0,size_noise, s)\n",
    "    #S[y==noise_id]=S[y==noise_id]+noise\n",
    "    return X, y, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2089068",
   "metadata": {},
   "source": [
    "## Choosing $X\\subseteq Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9aad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=1000\n",
    "print(\"Size of each class on input data:\")\n",
    "for i in set(labels):\n",
    "    print(\"Class \",i,\": \",np.sum(labels==i),\" proportion: \", np.sum(labels==i)/len(labels))\n",
    "X, y, X_indices = subsetZ(Z,labels,size)\n",
    "print(\"Size of each class on train data:\")\n",
    "for i in set(labels):\n",
    "    print(\"Class \",i,\": \",np.sum(y==i),\" proportion: \", np.sum(y==i)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71beeae7",
   "metadata": {},
   "source": [
    "## MLP training and performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fb65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test = np.array([Z[i] for i in range(len(Z)) if i not in X_indices])\n",
    "y_test = np.array([labels[i] for i in range(len(labels)) if i not in X_indices])\n",
    "input_dim = np.shape(X)[1]\n",
    "verbose = False\n",
    "epochs = 1000\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\",use_bias=True, input_shape=(input_dim,)))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\",use_bias=True))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\",use_bias=True))\n",
    "model.add(tf.keras.layers.Dense(n_classes-1, activation=\"softmax\",use_bias=True))\n",
    "\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              patience=10)\n",
    "\n",
    "\n",
    "opt  = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(\"Training neural network...\")\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "for i in range(10):\n",
    "    history = model.fit(X,y,epochs=epochs, verbose = verbose,callbacks=[callback])\n",
    "    acc_test.append(model.evaluate(Z_test,y_test)[1])\n",
    "    acc_train.append(model.evaluate(X,y)[1])\n",
    "i=np.argmax(acc_test)\n",
    "print(\"Acc on test: \",acc_test[i])\n",
    "print(\"Acc on train: \",acc_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "from matplotlib import colormaps\n",
    "conf_m=tf.math.confusion_matrix(y_test,[np.argmax(x) for x in model.predict(Z_test)])\n",
    "# get pandas dataframe\n",
    "df_cm = pd.DataFrame(conf_m, index=range(n_classes-1), columns=range(n_classes-1))\n",
    "#for i in range(len(list(colormaps))):\n",
    "#    print(i)\n",
    "cmap = list(colormaps)[2]\n",
    "pp_matrix(df_cm, cmap=cmap)\n",
    "plt.savefig(plots_dir + \"housing_conf_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8f1c3-de12-41f1-8f95-045092a73b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas`ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5c3cad",
   "metadata": {},
   "source": [
    "## $D(f)$ for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(labels):\n",
    "    print(\"Label: \",i)\n",
    "    Xi = X[y==i]\n",
    "    yi = y[y==i]\n",
    "    Zi = Z[labels==i]\n",
    "    Zi_indices = np.argwhere(labels==i).flatten() # Respect to X\n",
    "    Xi_indices = X_indices[y==i] # Respect to X\n",
    "    Xi_indices=[np.argwhere(Zi_indices==x).flatten()[0] for x in Xi_indices]\n",
    "    \n",
    "    \n",
    "    Xi_compl = np.ones(Zi.shape[0], dtype=\"bool\")\n",
    "    Xi_compl[Xi_indices] = False\n",
    "    Zi = np.vstack((Zi[Xi_indices], Zi[Xi_compl]))\n",
    "    Xi_indices = range(len(Xi_indices))\n",
    "    Xi = Zi[Xi_indices]\n",
    "    filt_Xi, filt_Zi, matchingi = tdqual.compute_Mf_0(Xi,Zi)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,2.5))\n",
    "    tdqual.plot_matching_0(filt_Xi, filt_Zi, matchingi, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(plots_dir + \"block_matching_0_c\"+str(i)+\".png\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    D_fi, multiplicitiesi = tdqual.compute_matching_diagram(filt_Xi, filt_Zi, matchingi, _tol=1e-5)\n",
    "    tdqual.plot_matching_diagram(D_fi, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(plots_dir + \"matching_diagram_0_c\"+str(i)+\".png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e6da96",
   "metadata": {},
   "source": [
    "## $D(f)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_compl = np.ones(Z.shape[0], dtype=\"bool\")\n",
    "X_compl[X_indices] = False\n",
    "Z = np.vstack((Z[X_indices], Z[X_compl]))\n",
    "X_indices_old = X_indices\n",
    "X_indices = range(len(X_indices))\n",
    "X = Z[X_indices]\n",
    "filt_X, filt_Z, matching = tdqual.compute_Mf_0(X,Z)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,2.5))\n",
    "tdqual.plot_matching_0(filt_X, filt_Z, matching, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plots_dir + \"block_matching_0.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "D_f, multiplicities = tdqual.compute_matching_diagram(filt_X, filt_Z, matching, _tol=1e-5)\n",
    "tdqual.plot_matching_diagram(D_f, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plots_dir + \"matching_diagram_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f334e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0095a-59ab-4a97-852a-7745db3c7342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
