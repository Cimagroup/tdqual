{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d590c372",
   "metadata": {},
   "source": [
    "# Beans dataset experiment\n",
    "\n",
    "In this notebook we will try to study the relationship between a given subset $X$ of a dataset $Z$ and the whole dataset. The steps will be the following:\n",
    "1. Load the dataset and normalize its values.\n",
    "2. Explore the dataset using UMAP.\n",
    "3. Choose a random subset of the dataset of a given size.\n",
    "4. Train a MLP on the random subset as a train set and use the rest as test.\n",
    "5. Study the partial matching between the persistence diagrams for the qualitative study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1fe51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import scipy.spatial.distance as dist\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import gudhi\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import scipy.spatial.distance as dist\n",
    "import itertools\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "\n",
    "import tdqual.topological_data_quality_0 as tdqual\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plots_dir = \"beans_images/\"\n",
    "\n",
    "dry_bean = fetch_ucirepo(id=602) \n",
    "Z=dry_bean[\"data\"]\n",
    "Z = preprocessing.normalize(dry_bean.data.features) \n",
    "y=dry_bean.data.targets \n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "labels = le.transform(y)\n",
    "\n",
    "\n",
    "def subsetZ(Z,labels,size):#,noise_id, size_noise):\n",
    "    ids = np.random.choice(len(Z), replace=False, size=size)\n",
    "    X=Z[ids]\n",
    "    y=labels[ids]\n",
    "    #s=np.shape(S[y==noise_id])\n",
    "    #noise = np.random.normal(0,size_noise, s)\n",
    "    #S[y==noise_id]=S[y==noise_id]+noise\n",
    "    return X, y, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c64a1",
   "metadata": {},
   "source": [
    "## Choosing $X\\subseteq Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e46b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of each class on input data:\")\n",
    "for i in set(labels):\n",
    "    print(\"Class \",i,\": \",np.sum(labels==i),\" proportion: \", np.sum(labels==i)/len(labels))\n",
    "size=3000\n",
    "n_classes= len(set(labels))\n",
    "X, y, X_indices = subsetZ(Z,labels,size)\n",
    "print(\"Size of each class on train data:\")\n",
    "for i in set(labels):\n",
    "    print(\"Class \",i,\": \",np.sum(y==i),\" proportion: \", np.sum(y==i)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2936f",
   "metadata": {},
   "source": [
    "### UMAP embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "reducer = umap.UMAP(n_neighbors=100,n_components=2)\n",
    "embedding = reducer.fit_transform(X)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84040e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(embedding[S_indices[y==i]][:,0],embedding[X_indices[y==i]][:,1],'.')\n",
    "    ax2.plot(embedding[labels==i][:,0],embedding[labels==i][:,1],'.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e1626",
   "metadata": {},
   "source": [
    "## MLP training and performance measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_test = np.array([Z[i] for i in range(len(Z)) if i not in X_indices])\n",
    "y_test = np.array([labels[i] for i in range(len(labels)) if i not in X_indices])\n",
    "input_dim = np.shape(X)[1]\n",
    "verbose = False\n",
    "epochs = 1000\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation=\"relu\",use_bias=True, input_shape=(input_dim,)))\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\",use_bias=True, input_shape=(input_dim,)))\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\",use_bias=True))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\",use_bias=True))\n",
    "model.add(tf.keras.layers.Dense(n_classes, activation=\"softmax\",use_bias=True))\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              patience=10)\n",
    "\n",
    "\n",
    "opt  = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "print(\"Training neural network...\")\n",
    "acc_test = []\n",
    "acc_train = []\n",
    "for i in range(10):\n",
    "    history = model.fit(X,y,epochs=epochs, verbose = verbose,callbacks=[callback])\n",
    "    acc_test.append(model.evaluate(Z_test,y_test)[1])\n",
    "    acc_train.append(model.evaluate(X,y)[1])\n",
    "i=np.argmax(acc_test)\n",
    "print(\"Acc on test: \",acc_test[i])\n",
    "print(\"Acc on train: \",acc_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf294c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "from matplotlib import colormaps\n",
    "conf_m=tf.math.confusion_matrix(y_test,[np.argmax(z) for z in model.predict(Z_test)])\n",
    "# get pandas dataframe\n",
    "df_cm = pd.DataFrame(conf_m, index=range(n_classes), columns=range(n_classes))\n",
    "#for i in range(len(list(colormaps))):\n",
    "#    print(i)\n",
    "cmap = list(colormaps)[2]\n",
    "pp_matrix(df_cm, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938eb67f",
   "metadata": {},
   "source": [
    "## $D(f)$ for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c842f6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in set(labels):\n",
    "    print(\"Label: \",i)\n",
    "    Xi = X[y==i]\n",
    "    yi = y[y==i]\n",
    "    Zi = Z[labels==i]\n",
    "    Zi_indices = np.argwhere(labels==i).flatten() # Respect to X\n",
    "    Xi_indices = X_indices[y==i] # Respect to X\n",
    "    Xi_indices=[np.argwhere(Zi_indices==x).flatten()[0] for x in Xi_indices]\n",
    "    \n",
    "    \n",
    "    Xi_compl = np.ones(Zi.shape[0], dtype=\"bool\")\n",
    "    Xi_compl[Xi_indices] = False\n",
    "    Zi = np.vstack((Zi[Xi_indices], Zi[Xi_compl]))\n",
    "    Xi_indices = range(len(Xi_indices))\n",
    "    Xi = Zi[Xi_indices]\n",
    "    filt_Xi, filt_Zi, matchingi = tdqual.compute_Mf_0(Xi,Zi)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,2.5))\n",
    "    tdqual.plot_matching_0(filt_Xi, filt_Zi, matchingi, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(plots_dir + \"block_matching_0_c\"+str(i)+\".png\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    D_fi, multiplicitiesi = tdqual.compute_matching_diagram(filt_Xi, filt_Zi, matchingi, _tol=1e-5)\n",
    "    tdqual.plot_matching_diagram(D_fi, ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(plots_dir + \"matching_diagram_0_c\"+str(i)+\".png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7eac3",
   "metadata": {},
   "source": [
    "## $D(f)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737384eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_compl = np.ones(Z.shape[0], dtype=\"bool\")\n",
    "X_compl[X_indices] = False\n",
    "Z = np.vstack((Z[X_indices], Z[X_compl]))\n",
    "X_indices_old = X_indices\n",
    "X_indices = range(len(X_indices))\n",
    "X = Z[X_indices]\n",
    "filt_X, filt_Z, matching = tdqual.compute_Mf_0(X,Z)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,2.5))\n",
    "tdqual.plot_matching_0(filt_X, filt_Z, matching, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plots_dir + \"block_matching_0.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "D_f, multiplicities = tdqual.compute_matching_diagram(filt_X, filt_Z, matching, _tol=1e-5)\n",
    "tdqual.plot_matching_diagram(D_f, ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plots_dir + \"matching_diagram_0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25be53e",
   "metadata": {},
   "source": [
    "## Umap embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "reducer = umap.UMAP(n_neighbors=100,n_components=2)\n",
    "embedding = reducer.fit_transform(X)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:,0],embedding[:,1],c=labels)\n",
    "plt.colorbar(boundaries=np.arange(8)-0.5).set_ticks(np.arange(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d957ce31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(embedding[S_indices[y==i]][:,0],embedding[X_indices[y==i]][:,1],'.')\n",
    "    ax2.plot(embedding[labels==i][:,0],embedding[labels==i][:,1],'.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6890faa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
